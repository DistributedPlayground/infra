version: '3.8'
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    # Not working
    # healthcheck:
    #   test: ["CMD", "zkCli.sh", "ls", "/"]
    #   interval: 15s
    #   timeout: 15s
    #   retries: 10
    #   start_period: 30s

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    # depends_on:
    #   zookeeper:
    #     condition: service_healthy
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:9092", "--list"]
      interval: 15s
      timeout: 15s
      retries: 10
      start_period: 30s

  product-db:
    image: postgres:14.1-alpine
    restart: always
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - '5432:5432'
    volumes:
      - product-db:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}" ]
      interval: 15s
      timeout: 15s
      retries: 10
      start_period: 30s

  product-migrations:
    build:
      context: ../../product-migrations/
      dockerfile: local.Dockerfile
    container_name: product-migrations
    depends_on:
      product-db:
        condition: service_healthy

  products:
    build:
      context: ../../products/
      dockerfile: local.Dockerfile
    container_name: products
    ports:
      - 5555:5555 # api port
      - 2345:2345 # debug port
    depends_on:
      product-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ../../products/:/products

  inventory-db:
    image: redis:7.0-alpine
    restart: always
    ports:
      - '6379:6379'
    volumes:
      - inventory-db:/data
    command: redis-server --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping" ]
      interval: 15s
      timeout: 15s
      retries: 10
      start_period: 30s
  
  inventory:
    build:
      context: ../../inventory/
      dockerfile: local.Dockerfile
    container_name: inventory
    ports:
      - 5556:5556 # api port
      - 2346:2346 # debug port
    depends_on:
      inventory-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ../../inventory/:/inventory

  product-search-db:
    image: mongo:latest
    environment:
      MONGO_INITDB_DATABASE: ${MONGO_DB}
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    ports:
      - "27017:27017"
    volumes:
      - product-search-db:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh --username=${MONGO_USER} --password=${MONGO_PASSWORD} --host=localhost --port=27017 --quiet
      interval: 15s
      timeout: 15s
      retries: 10
      start_period: 30s

  product-search:
    build:
      context: ../../product-search/
      dockerfile: local.Dockerfile
    container_name: product-search
    ports:
      - 5557:5557 # api port
      - 2347:2347 # debug port
    depends_on:
      product-search-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ../../product-search/:/product-search

volumes:
  product-db:
    driver: local
    ## We want the Redis data not to persist. 
    ## Commenting out the lines below is equivalent to run the command FLUSHALL after each restart
    ## Uncomment the following lines to persist data
  inventory-db:
    driver: local
  product-search-db:
    driver: local
